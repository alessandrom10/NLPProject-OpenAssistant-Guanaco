{"cells":[{"cell_type":"markdown","metadata":{"id":"Ix2ho3LYY5eA"},"source":["Install the required packages:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68969,"status":"ok","timestamp":1716024791656,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-120},"id":"NGC_prclTKhr","outputId":"7ae50de6-b078-41ff-ce8d-e2f6a0a9e2f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -U torch torchvision\n","!pip install -q -U bitsandbytes trl\n","!pip install -q datasets\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U langdetect"]},{"cell_type":"code","source":["!pip install -U torch\n","#!pip install -U torch torch_xla"],"metadata":{"id":"rsA0hR0vyTYt","executionInfo":{"status":"ok","timestamp":1716024797175,"user_tz":-120,"elapsed":5524,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fe4e0daf-7aff-4887-912b-05a9def4b563"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip install huggingface_hub\n","from huggingface_hub import login, logout\n","login(\"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\")\n","# !huggingface-cli login --token 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"],"metadata":{"id":"fxJ4h0q0GJkM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716024802525,"user_tz":-120,"elapsed":5356,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"outputId":"ae6da9bf-35f3-4d5c-8fa8-26b9a4909b50"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n","The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: read).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"markdown","metadata":{"id":"9VfKfqY2Y9Kk"},"source":["Import the required modules:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"IyeqM5JfsQj4","executionInfo":{"status":"ok","timestamp":1716024809878,"user_tz":-120,"elapsed":7358,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}}},"outputs":[],"source":["import torch\n","\n","\"\"\"import torch_xla\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.parallel_loader as pl\n","import torch_xla.distributed.data_parallel as dp\n","import torch_xla.utils.serialization as xser\n","import torch_xla.debug.metrics as met\"\"\"\n","\n","from datasets import load_dataset\n","from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, Trainer, TrainingArguments\n","from trl import SFTTrainer\n","from langdetect import detect, LangDetectException"]},{"cell_type":"markdown","metadata":{"id":"T-y5SsKmRGLq"},"source":["Connect to Google Drive:"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"_kQs-EqmKnoM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716024812346,"user_tz":-120,"elapsed":2473,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"outputId":"3c014fbf-0876-42da-e0bf-fb4e3c1bf8b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/Colab Notebooks/NLP/Project\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/My Drive/Colab Notebooks/NLP/Project'"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"fyr5o0mAtFwJ","executionInfo":{"status":"ok","timestamp":1716024812346,"user_tz":-120,"elapsed":7,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}}},"outputs":[],"source":["# This function returns the language that is idenitfied for the given sentence\n","def detect_language(sentence):\n","    if isinstance(sentence, str):\n","        try:\n","            return detect(sentence)\n","        except LangDetectException:\n","            print(f\"Unknown: {sentence}\")\n","            return \"unknown\"\n","    else:\n","        print(f\"Numbers: {sentence}\")\n","        return \"unknown\""]},{"cell_type":"code","execution_count":7,"metadata":{"id":"enzAIMcVs5zj","executionInfo":{"status":"ok","timestamp":1716024812347,"user_tz":-120,"elapsed":8,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}}},"outputs":[],"source":["def is_language(sentence, language):\n","    if detect_language(sentence) == language:\n","        return True\n","    else:\n","        return False"]},{"cell_type":"markdown","metadata":{"id":"15itSxjMydYf"},"source":["We load the openassistant-guanaco dataset:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"0Vqm91zpycjR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716024828778,"user_tz":-120,"elapsed":16438,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"outputId":"f357890d-4255-46dc-b294-044c002287df"},"outputs":[{"output_type":"stream","name":"stderr","text":["Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n","Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"]}],"source":["dataset_name = \"timdettmers/openassistant-guanaco\"\n","dataset_train = load_dataset(dataset_name, split=\"train\") # We take only the train split of the dataset\n","dataset_test = load_dataset(dataset_name, split=\"test\")\n","\n","dataset_english_train = dataset_train.filter(lambda example: is_language(example['text'], \"en\"))\n","dataset_english_test = dataset_test.filter(lambda example: is_language(example['text'], \"en\"))"]},{"cell_type":"code","source":["#model_id = \"EleutherAI/gpt-neox-20b\"\n","model_id = \"meta-llama/Meta-Llama-3-8B\"\n","\n","# We set the configuration for ourt quantization\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","#device = xm.xla_device()\n","\n","model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n","\n","#model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n","\n","model.config.use_cache = False\n","tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"\n","terminators = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]"],"metadata":{"id":"qeql2MFHFsGn","executionInfo":{"status":"ok","timestamp":1716024843326,"user_tz":-120,"elapsed":14577,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["f1655b9a236046678ac1acc5bba54764","22eb75ff73fe4ae8a27375109734ed10","bcb4318319a0445e9773289feca4f5d2","c00e8b8892ba4c85a702672763e4d181","e3dbb7dd3a0d4501859dd70294e22db8","a1871c8a59194ce0abb716ddb308e94a","4d3d942224064c0d958916352bae301e","4a66eb74d3384cb8b64313c07dbfeba9","93921666c5f9455098c5400be44b2b0c","5efaf38bae9b4e429072397a79591a4a","81e540e9a62c4be38ebce5121b3bb3cd"]},"outputId":"55b2696d-fb92-4de6-9898-748bb4b8fa63"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1655b9a236046678ac1acc5bba54764"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["tmp = []"],"metadata":{"id":"Tte0yT3MCSdo","executionInfo":{"status":"ok","timestamp":1716024843328,"user_tz":-120,"elapsed":59,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["for entry in dataset_english_train[\"text\"]:\n","  tmp.append(entry)"],"metadata":{"id":"6rj3QuGSBYqW","executionInfo":{"status":"ok","timestamp":1716024843329,"user_tz":-120,"elapsed":55,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["len(tmp)"],"metadata":{"id":"0Mzp5qEHCXGg","executionInfo":{"status":"ok","timestamp":1716024843331,"user_tz":-120,"elapsed":55,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae2c793f-d33f-4338-e20a-24001733ba00"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3535"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import re\n","\n","# Function to transform dataset\n","def transform_dataset(dataset):\n","    transformed_data = []\n","\n","    for entry in dataset:\n","        # Split on the delimiter and remove empty strings\n","        parts = [part for part in re.split(r'###\\s*(Human|Assistant):', entry) if part.strip()]\n","\n","        # Iterator for parts to match roles with text\n","        tmp = []\n","        it = iter(parts)\n","        for role in it:\n","            content = next(it).strip()\n","            transformed_entry = {\n","                'role': 'assistant' if role.lower() == 'assistant' else 'user',\n","                'content': content\n","            }\n","            tmp.append(transformed_entry)\n","        transformed_data.append(tmp)\n","\n","    return transformed_data\n","\n","# Transform the dataset\n","transformed_dataset = transform_dataset(tmp)\n","print(transformed_dataset)\n"],"metadata":{"id":"ZukgmGLE--v6","executionInfo":{"status":"ok","timestamp":1716024843332,"user_tz":-120,"elapsed":55,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"91cf4d4b-fbab-4ce8-bba8-b9ab6acae21f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}]},{"cell_type":"code","source":["len(transformed_dataset)"],"metadata":{"id":"Z73RQbyiDjIh","executionInfo":{"status":"ok","timestamp":1716024843332,"user_tz":-120,"elapsed":52,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d3e77fff-1f45-4f43-c347-2c25c9d54eed"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3535"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["dataset_applied = []"],"metadata":{"id":"2SVTxSLiCp9H","executionInfo":{"status":"ok","timestamp":1716024843333,"user_tz":-120,"elapsed":51,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["for entry in transformed_dataset:\n","  dataset_applied.append(tokenizer.apply_chat_template(entry, add_generation_prompt=True, tokenize=False))"],"metadata":{"id":"EoVG-FmJCwQz","executionInfo":{"status":"ok","timestamp":1716024843333,"user_tz":-120,"elapsed":50,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7961e77b-d15d-4700-f98b-274fceeb0457"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["No chat template is set for this tokenizer, falling back to a default class-level template. This is very error-prone, because models are often trained with templates different from the class default! Default chat templates are a legacy feature and will be removed in Transformers v4.43, at which point any code depending on them will stop working. We recommend setting a valid chat template before then to ensure that this model continues working without issues.\n"]}]},{"cell_type":"code","source":["tokenizer.apply_chat_template(transformed_dataset[0], add_generation_prompt=True, tokenize=False)"],"metadata":{"id":"nzT_3Kai_R9K","executionInfo":{"status":"ok","timestamp":1716024843334,"user_tz":-120,"elapsed":49,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/","height":174},"outputId":"62fc4892-853f-4b09-a2cb-08951c1d2b8b"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|im_start|>user\\nCan you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.<|im_end|>\\n<|im_start|>assistant\\n\"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.<|im_end|>\\n<|im_start|>user\\nNow explain it to a dog<|im_end|>\\n<|im_start|>assistant\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["len(dataset_applied)"],"metadata":{"id":"jeClGe2_C8-d","executionInfo":{"status":"ok","timestamp":1716024843334,"user_tz":-120,"elapsed":23,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"28965da6-3a76-4d8a-d770-9cc9d4aec708"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3535"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["type(dataset_applied)"],"metadata":{"id":"eLC4kQrFD8Fm","executionInfo":{"status":"ok","timestamp":1716024843334,"user_tz":-120,"elapsed":20,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff25552e-5ce2-4b44-ee63-b4febcd0308a"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["from datasets import Dataset\n","dataset = Dataset.from_dict({'text': dataset_applied})\n","\n","# Tokenize the data\n","def tokenize_function(examples):\n","    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n","\n","# Apply the tokenizer\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n"],"metadata":{"id":"JvV5-MssFCWv","executionInfo":{"status":"ok","timestamp":1716024844793,"user_tz":-120,"elapsed":1477,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e2da7029d5b546a18ef21de4a5a2d61a","9452b40fa3cf4791871e8fa978f1db17","3227913765f249e48ef21c62c7249ba7","c5dab1ed58ff4d709a010c493dbf89b1","88aff221642f454a9b98cc6111949ddd","b161fcc1eb364fc2b458c3f983bf439b","01c44c17226546439919b62c7aebfa57","dfee52ad20bb4cd3ac4d6d2560e2a33f","365295a789e84e4e89e4cffe670a7e85","62078d4ca24c4814b72e959adf8565ff","d83753bff3e546209ddc9c15e29ceed4"]},"outputId":"ed345b7f-8dea-4452-ded5-30ac25068255"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3535 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2da7029d5b546a18ef21de4a5a2d61a"}},"metadata":{}}]},{"cell_type":"code","source":["dataset"],"metadata":{"id":"_tU9JhZKFER5","executionInfo":{"status":"ok","timestamp":1716024844794,"user_tz":-120,"elapsed":26,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2f0c9f1-d89c-4446-8a15-8ad7eeb17f97"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['text'],\n","    num_rows: 3535\n","})"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["tokenized_dataset"],"metadata":{"id":"TGRDnjaNFKWM","executionInfo":{"status":"ok","timestamp":1716024844794,"user_tz":-120,"elapsed":23,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ce24516-d10c-4620-af9c-dfd4a65394ca"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['text', 'input_ids', 'attention_mask'],\n","    num_rows: 3535\n","})"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["dataset_english_train"],"metadata":{"id":"7mFJ2A-b-CSb","executionInfo":{"status":"ok","timestamp":1716024844794,"user_tz":-120,"elapsed":20,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dfecb0f5-c0c6-4761-98dc-0540d238819a"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['text'],\n","    num_rows: 3535\n","})"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["dataset_english_train[\"text\"][0]"],"metadata":{"id":"3Sk7RiQJ9t8U","executionInfo":{"status":"ok","timestamp":1716024844795,"user_tz":-120,"elapsed":15,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/","height":174},"outputId":"7d781228-b179-4af2-f396-0c686a1eafed"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"-Bnwn1S4wpJv"},"source":["Models to try: Falcon, LLM2, LLM3, gpt-2\n","\n","We load he required model with 4-bit quantization:"]},{"cell_type":"markdown","metadata":{"id":"ZhQkwepAxip1"},"source":["We enable gradient checkpointing to save additional memory (it's a pretty standard thing to do) and we prepare the model for training (so we convert its parameters to 16 bit i think):"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"prPg4_znxgVq","executionInfo":{"status":"ok","timestamp":1716024844795,"user_tz":-120,"elapsed":12,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}}},"outputs":[],"source":["# Enabling the gradient checkpointing allow us to recompute some values of the neural network when needed, instead of storing them all and copnsuming a lot of memory\n","model.gradient_checkpointing_enable()\n","\n","# This prepares the model for the kbit trainig\n","model = prepare_model_for_kbit_training(model)"]},{"cell_type":"markdown","metadata":{"id":"7IhnoPxlw7um"},"source":["Function to print the number and percentage of trainable parameters:"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"P5CbbSB_ZbCe","executionInfo":{"status":"ok","timestamp":1716024846409,"user_tz":-120,"elapsed":1625,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}}},"outputs":[],"source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"]},{"cell_type":"markdown","metadata":{"id":"pBtxkbp9xHt_"},"source":["We set the config that are gonna be uses with LoRA:"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"OTDoUGNeZbce","executionInfo":{"status":"ok","timestamp":1716024846410,"user_tz":-120,"elapsed":11,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"44e4fb98-4db9-4c83-88f2-5635bc593c29"},"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 54525952 || all params: 4595126272 || trainable%: 1.1866039967660762\n"]}],"source":["lora_alpha = 16\n","lora_dropout = 0.1\n","lora_r = 64\n","\n","peft_config = LoraConfig(\n","    lora_alpha=lora_alpha,\n","    lora_dropout=lora_dropout,\n","    r=lora_r,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    #target_modules=[\n","    #   \"query_key_value\",\n","    #    \"dense\",\n","    #    \"dense_h_to_4h\",\n","    #    \"dense_4h_to_h\",\n","    #]\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",")\n","\n","# And using this config we obtain the LoRA trainable version of the model\n","model = get_peft_model(model, peft_config)\n","print_trainable_parameters(model)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"sd-6HQW-zhd4","executionInfo":{"status":"ok","timestamp":1716024846410,"user_tz":-120,"elapsed":10,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}}},"outputs":[],"source":["output_dir = \"./results\"\n","#per_device_train_batch_size = 13\n","per_device_train_batch_size = 4\n","gradient_accumulation_steps = 3\n","optim = \"paged_adamw_32bit\"\n","save_steps = 10\n","logging_steps = 10\n","learning_rate = 2e-5\n","max_grad_norm = 0.3\n","max_steps = 500\n","#max_steps = 250\n","warmup_ratio = 0.03\n","lr_scheduler_type = \"constant\"\n","\n","training_arguments = TrainingArguments(\n","    output_dir = output_dir,\n","    per_device_train_batch_size = per_device_train_batch_size,\n","    gradient_accumulation_steps = gradient_accumulation_steps,\n","    optim = optim,\n","    save_steps = save_steps,\n","    logging_steps = logging_steps,\n","    learning_rate = learning_rate,\n","    fp16 = True,\n","    max_grad_norm = max_grad_norm,\n","    max_steps = max_steps,\n","    warmup_ratio = warmup_ratio,\n","    group_by_length = True,\n","    lr_scheduler_type = lr_scheduler_type,\n","    gradient_checkpointing = True,\n",")"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"wvnhdeCDzvoT","executionInfo":{"status":"ok","timestamp":1716024846411,"user_tz":-120,"elapsed":10,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"050c6922-1db5-4dfa-e4ce-51e447908743"},"outputs":[{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["max_seq_length = 512\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    train_dataset = tokenized_dataset,\n","    peft_config = peft_config,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    tokenizer = tokenizer,\n","    args = training_arguments,\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"mnHh8Nenz34I","executionInfo":{"status":"ok","timestamp":1716024846411,"user_tz":-120,"elapsed":7,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}}},"outputs":[],"source":["for name, module in trainer.model.named_modules():\n","    if \"norm\" in name:\n","        module = module.to(torch.float32)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"SsYuzPLZ0HRZ","executionInfo":{"status":"ok","timestamp":1716035739515,"user_tz":-120,"elapsed":10892549,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"384ca2ca-327f-4209-a219-60464d8529c5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 3:01:11, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.467400</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.392500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.359600</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.238800</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.286200</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.180700</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>1.250400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.164000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.161700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.235500</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>1.209000</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.233600</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>1.191700</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>1.238100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.201600</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.086700</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>1.183700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.239900</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>1.222300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.201900</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>1.203400</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>1.189100</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>1.250900</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.219400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.193300</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>1.151600</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>1.168400</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>1.158000</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>1.188100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.204600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>1.160700</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>1.271100</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>1.175900</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>1.076200</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.155800</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>1.195800</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>1.144800</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>1.163000</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>1.120600</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.126700</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>1.129900</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>1.137900</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>1.145300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>1.178800</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.194000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>1.136600</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>1.183600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>1.168200</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>1.166000</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.192800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=1.1979184608459472, metrics={'train_runtime': 10890.1508, 'train_samples_per_second': 0.551, 'train_steps_per_second': 0.046, 'total_flos': 1.3931257126925107e+17, 'train_loss': 1.1979184608459472, 'epoch': 1.6968325791855203})"]},"metadata":{},"execution_count":31}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"t_6U-s9yKeSM","executionInfo":{"status":"ok","timestamp":1716035741172,"user_tz":-120,"elapsed":1683,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5b66bf1-1eda-46e8-b775-7f4ca18971a7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["# Save the model in a format suitable for inference\n","output_model_dir = \"Saved_models/llama-8-finetuned-onlyEnglish\"\n","model.save_pretrained(output_model_dir)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"GeabGaWU6Im4","executionInfo":{"status":"ok","timestamp":1716035741173,"user_tz":-120,"elapsed":18,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"15c70de5-6f30-4e22-b6a0-ab79d73f8b39"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# Define your prompt\\nprompt = \"### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\"\\n\\n# Tokenize the prompt\\ninput_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\\n\\n# Generate text based on the prompt\\noutput = model.generate(\\n    input_ids,\\n    max_length=100,\\n    num_return_sequences=1\\n)\\n\\n# Decode the generated text\\ngenerated_text = tokenizer.decode(output[0], skip_special_tokens=True)\\n\\n# Print the generated text\\nprint(\"Generated text:\", generated_text)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}],"source":["\"\"\"# Define your prompt\n","prompt = \"### Human: Can you write a short introduction about the relevance of the term \\\"monopsony\\\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\"\n","\n","# Tokenize the prompt\n","input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","# Generate text based on the prompt\n","output = model.generate(\n","    input_ids,\n","    max_length=100,\n","    num_return_sequences=1\n",")\n","\n","# Decode the generated text\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","# Print the generated text\n","print(\"Generated text:\", generated_text)\"\"\""]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1kNhNb1n1Alfb4YukjIfLsySKbfigM5X7","timestamp":1715957437906}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f1655b9a236046678ac1acc5bba54764":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22eb75ff73fe4ae8a27375109734ed10","IPY_MODEL_bcb4318319a0445e9773289feca4f5d2","IPY_MODEL_c00e8b8892ba4c85a702672763e4d181"],"layout":"IPY_MODEL_e3dbb7dd3a0d4501859dd70294e22db8"}},"22eb75ff73fe4ae8a27375109734ed10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1871c8a59194ce0abb716ddb308e94a","placeholder":"​","style":"IPY_MODEL_4d3d942224064c0d958916352bae301e","value":"Loading checkpoint shards: 100%"}},"bcb4318319a0445e9773289feca4f5d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a66eb74d3384cb8b64313c07dbfeba9","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93921666c5f9455098c5400be44b2b0c","value":4}},"c00e8b8892ba4c85a702672763e4d181":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5efaf38bae9b4e429072397a79591a4a","placeholder":"​","style":"IPY_MODEL_81e540e9a62c4be38ebce5121b3bb3cd","value":" 4/4 [00:12&lt;00:00,  2.59s/it]"}},"e3dbb7dd3a0d4501859dd70294e22db8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1871c8a59194ce0abb716ddb308e94a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d3d942224064c0d958916352bae301e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a66eb74d3384cb8b64313c07dbfeba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93921666c5f9455098c5400be44b2b0c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5efaf38bae9b4e429072397a79591a4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81e540e9a62c4be38ebce5121b3bb3cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2da7029d5b546a18ef21de4a5a2d61a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9452b40fa3cf4791871e8fa978f1db17","IPY_MODEL_3227913765f249e48ef21c62c7249ba7","IPY_MODEL_c5dab1ed58ff4d709a010c493dbf89b1"],"layout":"IPY_MODEL_88aff221642f454a9b98cc6111949ddd"}},"9452b40fa3cf4791871e8fa978f1db17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b161fcc1eb364fc2b458c3f983bf439b","placeholder":"​","style":"IPY_MODEL_01c44c17226546439919b62c7aebfa57","value":"Map: 100%"}},"3227913765f249e48ef21c62c7249ba7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfee52ad20bb4cd3ac4d6d2560e2a33f","max":3535,"min":0,"orientation":"horizontal","style":"IPY_MODEL_365295a789e84e4e89e4cffe670a7e85","value":3535}},"c5dab1ed58ff4d709a010c493dbf89b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62078d4ca24c4814b72e959adf8565ff","placeholder":"​","style":"IPY_MODEL_d83753bff3e546209ddc9c15e29ceed4","value":" 3535/3535 [00:01&lt;00:00, 2500.68 examples/s]"}},"88aff221642f454a9b98cc6111949ddd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b161fcc1eb364fc2b458c3f983bf439b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01c44c17226546439919b62c7aebfa57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfee52ad20bb4cd3ac4d6d2560e2a33f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"365295a789e84e4e89e4cffe670a7e85":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62078d4ca24c4814b72e959adf8565ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d83753bff3e546209ddc9c15e29ceed4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}